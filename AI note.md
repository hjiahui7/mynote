---
number headings: auto, first-level 1, max 6, 1.1
---


# 1 RL çŸ¥è¯†æ¢³ç†


 1.1 Top Down
![[Pasted image 20250927014929.png]]

# 2 ç»Ÿä¸€æ¡†æ¶ï¼ˆæ€»è§ˆï¼‰

> ç›®æ ‡ï¼šåœ¨é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ä¸­æœ€å¤§åŒ–æœŸæœ›å›æŠ¥  
> \(J(\pi)=\mathbb{E}_{\tau\sim \pi}\!\left[\sum_{t=0}^{T-1}\gamma^{t}\,r_{t+1}\right]\)

- ä¸¤æ¡ä¸»çº¿ï¼šValue-basedï¼ˆc2aï¼šå…ˆå­¦å€¼åå‡ºç­–ï¼‰ä¸ Policy-basedï¼ˆa2cï¼šå…ˆå»ºç­–å†ç”¨å€¼é™æ–¹å·®ï¼‰ã€‚
- ä¸‰æ¡æ¨ªè½´ï¼šMC vs TDã€On-policy vs Off-policyã€ç¨³å®šæ€§ï¼ˆKL/ç†µ/è‡´å‘½ä¸‰è§’ï¼‰ã€‚
- æ ¸å¿ƒå¾ªç¯ï¼šå¹¿ä¹‰ç­–ç•¥è¿­ä»£ï¼ˆGPIï¼‰= è¯„ä¼°ï¼ˆå­¦ V/Q/Advï¼‰â†’ æ”¹è¿›ï¼ˆgreedy/softmax æˆ– ç­–ç•¥æ¢¯åº¦ï¼‰â†’ é‡å¤ã€‚


 2.1 Value-basedï¼ˆ**c2aï¼šCritic â†’ Actor**ï¼‰
- **æ€è·¯**ï¼šå…ˆå­¦ä¹ å€¼å‡½æ•°ï¼ˆQ æˆ– VVVï¼‰ï¼Œå†ç”¨ **greedy / Ïµ\epsilonÏµ-greedy / softmax** ä»å€¼å‡½æ•°**å¯¼å‡º**ç­–ç•¥ã€‚
- **ä»£è¡¨**ï¼šMC Controlã€SARSAã€Expected SARSAã€Q-learningã€DQNï¼ˆ+ ç›®æ ‡ç½‘ç»œ/é‡æ”¾/Double-Qï¼‰ã€‚
- **ä¼˜ç‚¹**ï¼šç¦»æ•£åŠ¨ä½œç®€å•é«˜æ•ˆã€‚
- **å±€é™**ï¼šè¿ç»­åŠ¨ä½œ argâ¡maxâ¡aQ\arg\max_a Qargmaxaâ€‹Q å›°éš¾ï¼›ç­–ç•¥ä¸å¯ç›´æ¥æ­£åˆ™åŒ–ã€‚

 2.2 Policy-basedï¼ˆ**a2cï¼šActor â†’ Critic**ï¼‰

 2.3 Markov decision process








# 3 RL åŸºç¡€ ç¬¬äºŒç‰ˆæœ¬

https://www.bilibili.com/video/BV1rooaYVEk8/?spm_id_from=333.1387.homepage.video_card.click&vd_source=7edf748383cf2774ace9f08c7aed1476
## 3.1 Top down
![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=OTg4YmU4M2ZiMDIyZjZlNGRkOTUxMDlkOWRkOWIwOWRfNGNqa2h4dlhEQWZaeTZ4OHEwSnpYRnEwYnNsYXlUbzhfVG9rZW46THZNc2JmeFZ0b2tzeUV4SDdBWmxzQ3NPZ1FkXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

## 3.2 Markov decision process
![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=MWI2ZTdlMDBlYTBjMDE2ODAzM2IwZWQ0NTVlMGQ3ZjFfVXUwOHhMSXE3NU5laDZGT0lPVUs0VTl5YjNBMUpUc3VfVG9rZW46RW55SGJFRVdOb2ZFdHN4R3ROQmxDR3YzZ1ZmXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

## 3.3 State Value & Action Value
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=Yjc3NmZjNGVjMjQyMGY4ODE4ZmQwM2JkYTBmNTdjMGRfMzBUQ2x3WmU0NU9MUWhmWE5Od0pHdXFHb0FuUURiQ0ZfVG9rZW46WE9DOWJEOTBIbzBMQlB4RlQ3emxhcmkxZ2ZjXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

**Note:**

1. **ä»·å€¼å‡½æ•° (Value) V**ï¼š åœ¨çŠ¶æ€ s ä¸‹ï¼ŒæŒ‰ç…§ç­–ç•¥èµ°ä¸‹å»çš„**æ€»å›æŠ¥**ã€‚
	V(s)=R(s èµ·ç‚¹å¾€åç®—çš„æ€»å›æŠ¥)
2. **åŠ¨ä½œä»·å€¼å‡½æ•° (Q-value) Q**ï¼š åœ¨çŠ¶æ€ s ä¸‹ï¼Œå…ˆé€‰åŠ¨ä½œ aï¼Œå†æŒ‰ç…§ç­–ç•¥èµ°ä¸‹å»çš„**æ€»å›æŠ¥**ã€‚
	Q(s,a)=R(s,a èµ·ç‚¹å¾€åç®—çš„æ€»å›æŠ¥)
3. **ä¼˜åŠ¿å‡½æ•° (Advantage) A**ï¼š åŠ¨ä½œ a ç›¸æ¯”äºè¯¥çŠ¶æ€å¹³å‡æ°´å¹³çš„å¥½åã€‚
	A(s,a)=Q(s,a)âˆ’V(s)

4. ç›´è§‚å…³ç³»
    
    1. V(s)å¯ä»¥çœ‹æˆâ€œå¹³å‡æ°´å¹³â€ã€‚
    2. Q(s,a) æ˜¯â€œæŒ‡å®šåŠ¨ä½œçš„åˆ†æ•°â€ã€‚
        
    3. A(s,a)å°±æ˜¯â€œæŒ‡å®šåŠ¨ä½œåˆ†æ•° âˆ’ å¹³å‡æ°´å¹³â€ã€‚
        
    4. å…¶ä¸­çš„æ¯ä¸€æ­¥ï¼š $Q(s_t,a_t) = r_t + \gamma V(s_{t+1})$
        

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=MWJiMzcyN2VjY2MxNzFiMmJjNjhhN2RhM2M1MTBjZjRfaG1oYWhwRFVzR0pneGxoc0prNFQ5VWVnRlhjV1VoZXBfVG9rZW46U1o2MWJ5bTdnbzdrM3R4czVWTWxGVmRkZ3lkXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

4.  Value basedï¼šMC & TD
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=OTgxYjE5MmY3MDE1ODQzNTAwOGUzNDA5ODAyZTE1NmNfQTRBR2pmWkE4SklxcXdEaFlIN2EyWHpQSk42ZVZXUndfVG9rZW46S1R2dWJQYlZLb0tXQ0R4NmNjYmx1OFdoZ3hnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

1.  Monte Carlo
    

2. # REINFORCEï¼ˆpolicy basedï¼‰
    

**REINFORCE å°±æ˜¯æœ€åŸç”Ÿçš„ Monte Carlo æ–¹æ³•**â€”â€”å®ƒç”¨æ•´æ®µå›æŠ¥ï¼ˆreturnï¼‰åšæ— åçš„æ¢¯åº¦ä¼°è®¡ã€æ²¡æœ‰ criticã€ä¹Ÿä¸åš bootstrappingã€‚

1. ä¼˜åŒ–ç›®æ ‡
    

åœ¨ä¸€ä¸ª episodic MDP é‡Œï¼Œç­–ç•¥ Ï€Î¸ çš„**è½¨è¿¹**ä¸º $\tau=(s_0,a_0,r_1,\ldots,s_{T-1},a_{T-1},r_T)$ ç›®æ ‡æ˜¯æœ€å¤§åŒ–**æœŸæœ›æ€»å›æŠ¥**ï¼ˆä¹Ÿå¯å«æŠ˜æ‰£ï¼‰ï¼š

$J_{\text{true}}(\theta)=\mathbb{E}_{\tau\sim p_\theta(\tau)}\big[R(\tau)\big], \quad R(\tau)=\sum_{t=0}^{T-1}\gamma^t r_{t+1}$

è¿™é‡Œ pÎ¸(Ï„) æ˜¯åœ¨å½“å‰ç­–ç•¥ä¸ç¯å¢ƒè½¬ç§»ä¸‹ç”Ÿæˆè¯¥è½¨è¿¹çš„**æ¦‚ç‡å¯†åº¦**ï¼š

$p_\theta(\tau)=\rho(s_0)\prod_{t=0}^{T-1}\pi_\theta(a_t|s_t)\,P(s_{t+1}|s_t,a_t)$

æ‰€ä»¥æœ€ç»ˆæˆ‘ä»¬è¦è®©è¿™ä¸ªæœ€å¤§ï¼Œæ‰€ä»¥å¯¹å…¶æ±‚å¯¼å³å¯ï¼š

$J_{\text{true}}(\theta) = \sum_{index=0}^{N}p_\theta(\tau_{index})\big[R(\tau_{index})\big]$

2. æ±‚å¯¼è¿‡ç¨‹ï¼šç›®æ ‡çš„æ¢¯åº¦ï¼ˆlog-derivative trickï¼‰
    

  

æˆ‘ä»¬è¦ $\nabla_\theta J_{\text{true}}(\theta)$ï¼Œç”¨**ä¼¼ç„¶æ¯”æŠ€å·§**ï¼š

$\nabla_\theta J_{\text{true}} =\nabla_\theta \int p_\theta(\tau)R(\tau)\,d\tau =\int p_\theta(\tau)\,\nabla_\theta \log p_\theta(\tau)\,R(\tau)\,d\tau =\mathbb{E}_{\tau\sim p_\theta}\!\big[\nabla_\theta \log p_\theta(\tau)\,R(\tau)\big]$æ³¨æ„æ˜¯ $\mathbb{E}_{\tau\sim p_\theta}$

è€Œ

$\log p_\theta(\tau)=\log\rho(s_0)+\sum_{t=0}^{T-1}\log\pi_\theta(a_t|s_t)+\sum_{t=0}^{T-1}\log P(s_{t+1}|s_t,a_t)$

å¯¹ Î¸ æ±‚å¯¼æ—¶åªæœ‰ç­–ç•¥é¡¹ç•™ä¸‹ï¼š

$\nabla_\theta \log p_\theta(\tau)=\sum_{t=0}^{T-1}\nabla_\theta \log\pi_\theta(a_t|s_t)$

ä»£å›å»ï¼š

$\nabla_\theta J_{\text{true}} =\mathbb{E}_{\tau\sim p_\theta}\!\Big[\sum_{t=0}^{T-1}\nabla_\theta \log\pi_\theta(a_t|s_t)\,R(\tau)\Big]$

æ³¨æ„åç»­è®¡ç®—å¯èƒ½ä¼šå¿½ç•¥æœ€å¤–å±‚çš„Eï¼Œå› ä¸ºæˆ‘ä»¬çš„æ•°æ®éƒ½æ˜¯é€šè¿‡Pï¼ˆè¿™é‡Œä¸æ˜¯çŠ¶æ€è½¬ç§»å‡½æ•°ï¼Œæ˜¯ä¸Šé¢çš„è¿™ä¸ªè½¨è¿¹çš„**æ¦‚ç‡å¯†åº¦å‡½æ•°**ï¼‰è¿™ä¸ªå‡½æ•°çš„æ¦‚ç‡åˆ†å¸ƒæ¥å–æ ·çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±å¯ä»¥å¿½ç•¥ä»–äº†

è¿™å°±æ˜¯ **REINFORCE æ¢¯åº¦**çš„â€œè½¨è¿¹çº§â€å½¢å¼ã€‚ä¸ºäº†**é™æ–¹å·®**ï¼ŒæŠŠæ•´æ®µ R(Ï„)æ¢æˆâ€œä» t å¼€å§‹çš„ reward-to-go å°±æ˜¯æ­¥æ•°è¶Šè¿œÎ³è¶Šå¤§â€ï¼š

$G_t=\sum_{k=t}^{T-1}\gamma^{k-t} r_{k+1}, \quad \nabla_\theta J_{\text{true}} =\mathbb{E}_{\tau\sim p_\theta}\!\Big[\sum_{t=0}^{T-1}\nabla_\theta \log\pi_\theta(a_t|s_t)\,G_t\Big]$

äºæ˜¯æˆ‘ä»¬å¯ä»¥æŠŠ

$\boxed{\ J(\theta)\;\;\text{å®šä¹‰ä¸ºå…¶æ— å MC ä¼°è®¡å¯¹åº”çš„ç›®æ ‡ï¼š}\;\; J(\theta)=\mathbb{E}\!\Big[\sum_t G_t\,\log\pi_\theta(a_t|s_t)\Big]\ }$

ä¸ºä»€ä¹ˆæˆ‘ä»¬çš„ç›®æ ‡å‡½æ•°ç›´æ¥å˜æˆäº†è¿™æ ·å­å‘¢ï¼Ÿ

å› ä¸ºæˆ‘ä»¬å‘ç°é€šè¿‡**æŸä¸€ä¸ªå¼å­**åˆ©ç”¨**ä¼¼ç„¶æ¯”æŠ€å·§**æ±‚å¯¼åçš„å¼å­ä¸º $\quad \nabla_\theta J_{\text{true}} =\mathbb{E}_{\tau\sim p_\theta}\!\Big[\sum_{t=0}^{T-1}\nabla_\theta \log\pi_\theta(a_t|s_t)\,G_t\Big]$ï¼Œé‚£ä¹ˆè¿™ä¸ª**æŸä¸€ä¸ªå¼å­ä¸º** $J(\theta)=\mathbb{E}\!\Big[\sum_t G_t\,\log\pi_\theta(a_t|s_t)\Big]$ï¼Œç®€å•æ¥è¯´å°±æ˜¯æ±‚äº†åŠå¤©å‘ç°è¿™ä¸ªJ(Î¸)å¯ä»¥ç”±è¿™ä¸ªç®€å•å½¢å¼è¡¨è¾¾ï¼Œå¹¶ä¸”ä»–å’Œæœ€åˆçš„ä»–æ˜¯ç­‰ä»·çš„

æˆ‘ä»¬æ­¤æ—¶æ­¤åˆ»æ±‚å‡ºäº†å¯¼æ•°åï¼Œå°±å¯ä»¥ç”¨ä¼˜åŒ–å‡½æ•°æ›´æ–°å‚æ•°äº†

  

3. å®é™…æ€ä¹ˆåšï¼ˆREINFORCE ä¸€è½®ï¼‰
    
    1. **é‡‡æ ·** N æ¡è½¨è¿¹ {Ï„i}ï¼ˆæŒ‰å½“å‰ç­–ç•¥ï¼‰
        
    2. **å›æ”¾**ï¼šå¯¹æ¯æ¡ Ï„i å€’åºç®— $G_t^i$
        
    3. **ï¼ˆå¯é€‰ï¼‰åŸºçº¿**ï¼šç”¨ $G_t^i-b(s_t^i)$ é™æ–¹å·®
        
    4. **ä¼°è®¡æ¢¯åº¦**ï¼š
        
        Â Â Â Â $\widehat{\nabla_\theta J} =\frac{1}{N}\sum_{i=1}^N\sum_{t}(G_t^i-b(s_t^i))\,\nabla_\theta\log\pi_\theta(a_t^i|s_t^i)$
        
    1. **æ›´æ–°å‚æ•°**ï¼š $\theta\leftarrow\theta+\alpha\,\widehat{\nabla_\theta J}$
        

å…¨ç¨‹æ²¡æœ‰æ˜¾å¼å‡ºç° pÎ¸(Ï„)çš„æ•°å€¼è®¡ç®—ã€‚

  

  

2.  é™æ–¹å·®ï¼šBaseline â†’ Advantage â†’ GAE
    

3.  Advantage çš„ç”±æ¥
    

REINFORCE æ— åä½†æ–¹å·®å¤§ï¼Œå­¦ä¹ æŠ–ã€‚è¯´ç™½äº†å°±æ˜¯Gä¸€èˆ¬æƒ…å†µä¸‹å¯èƒ½æ˜¯ä¸€ä¸ªéå¸¸å¤§çš„å€¼ï¼Œæˆ‘ä»¬å¸Œæœ›é™ä½æ¢¯åº¦çš„å¹…åº¦ï¼Œæ‰€ä»¥éœ€è¦å¯¹ä»–è¿›è¡Œnormalizationï¼Œæ‰€ä»¥æ‰æœ‰äº†baselineè¿™ä¸ªä¸œè¥¿ã€‚ä¹Ÿå°±æ˜¯Advantage= Gtâˆ’V(st)ã€‚æˆ‘ä»¬ç”¨V(st)æ¥ä¼°è®¡æœªæ¥çš„æœŸæœ›å¥–åŠ±æ˜¯å¤šå°‘ï¼Œä¹Ÿå°±æ˜¯å¹³å‡å€¼ï¼Œå‡æ‰äº†ä¹‹åå°±æ˜¯X-E[X]ï¼Œçœ‹åˆ°æ²¡æœ‰ï¼Œéå¸¸åƒæ˜¯normalizationäº†ä¸€ä¸‹ã€‚è¿™é‡Œæˆ‘ä»¬æ‰ç¬¬ä¸€æ¬¡å¼•å…¥äº†A

**REINFORCEï¼ˆçº¯ MCï¼‰**ï¼šå³ä¾¿æœ‰ baselineï¼ˆå“ªæ€• Gtâˆ’V(st)ï¼Œåªè¦ä¼˜åŠ¿é‡Œçš„ Gtæ˜¯**æ•´æ®µå›æŠ¥**ï¼Œä½ ä»ç„¶**éœ€è¦ç­‰åˆ° episode ç»“æŸ**æ‰èƒ½ç®—å®Œ Gt å†æ›´æ–°ï¼ˆå¯ä»¥é€æ­¥ç´¯ç§¯ï¼Œä½†ç›®æ ‡ä¾èµ–æœªæ¥å®Œæ•´å›æŠ¥ï¼‰ã€‚

**Actorâ€“Criticï¼ˆTDï¼‰**ï¼š**ä¸€æ—¦æŠŠ Gt æ¢æˆ TD ç›®æ ‡ï¼ˆä¾‹å¦‚ç”¨ Î´t æˆ– n-step/GAE è¿‘ä¼¼ï¼‰ï¼Œä½ å°±è¿›å…¥äº† actorâ€“critic èŒƒå¼ï¼Œèƒ½å¤Ÿk æ­¥ä¸€æ›´ï¼Œç”šè‡³æ­¥æ­¥æ›´æ–°ã€‚**ã€‚å…³é”®æ˜¯æŠŠä¼˜åŠ¿ç”¨**TD æ®‹å·®**è¿‘ä¼¼ï¼Œå®Œå…¨ä¸å¿…ç­‰ episode ç»“æŸã€‚

ç›¸å½“äºæŠŠGtæ¢æˆ $r_{t+1} \;+\; \gamma\,V_\phi(s_{t+1})$

2.  (GAE)Generalized Advantage Estimation
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=MGNhZWEwMThkNzZmNWRiOWQ5ZGZhNDlkMTY5YTQ0ZTJfU0Z2ZGNJYlVTYUVJV2RaZkZ5bUtZbHdkM3dZeHRnN2tfVG9rZW46RUh3S2JUanQzb1Z5cXR4bGNPZWxBSkE5Z3ZnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

å®é™…å€¼-æœŸæœ›å€¼=At advantageï¼Œä¼˜åŠ¿ï¼Œå¦‚æœ>0ï¼Œè¯´æ˜åœ¨å½“å‰sçš„æƒ…å†µä¸‹ï¼Œé€‰æ‹©actionæ˜¯æœ‰åˆ©çš„ï¼Œå¦‚æœ<0ï¼Œåˆ™æ˜¯ç”±penalty

3.  Aï¼ŒVï¼ŒQçš„å…³ç³»
    

æœ¬è´¨å°±æ˜¯Aæ˜¯ç”±G - baselineå¾—å‡ºçš„ï¼Œå…¶ä¸­G,baselineå¯ä»¥æ˜¯r+Q(st+1,at+1), Q(st,at)æˆ–è€…r+V(st+1), V(s)éƒ½è¡Œ.

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=MThiMmUyOTMwN2M1NTBiMmRlMWIwYzY3OWUzY2Q5ZjRfUXl1aU9FcUFaMU8zRU43R1lENDRxa0hOeWFYaDBoZmRfVG9rZW46WTZ3N2JMYXo2b0dLaEt4UmUya2x4NUdSZ1pmXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

4.  å¦‚ä½•ç†è§£æ–¹å·®å’Œåå·®
    

- **Monte Carlo**ï¼š
    
    - Q æ˜¯é€šè¿‡å®Œæ•´è½¨è¿¹çš„ return U æ¥ä¼°è®¡çš„ã€‚
        
    - æ¯æ¡è½¨è¿¹å¯èƒ½å¾ˆä¸åŒ â†’ **æ–¹å·®é«˜**ã€‚
        
    - ä½†æœŸæœ›å€¼ç­‰äºçœŸå®å€¼ â†’ **æ— å**ã€‚
        
- **TD**ï¼š
    
    - Qæ˜¯é€šè¿‡ bootstrappingä¼°è®¡æ¯ä¸€æ­¥çš„Q(st,at)ï¼Œå®ƒä¸æ˜¯â€œçœŸå®çš„æœªæ¥å›æŠ¥â€ï¼Œè€Œæ˜¯**æ¨¡å‹è‡ªå·±å¯¹æœªæ¥çš„ä¼°è®¡**ã€‚
        
        - rt+Î³Q(st+1,at+1)
            
    - ç”±äºç”¨çš„æ˜¯è‡ªå·±çš„ä¼°è®¡ Qï¼Œæ‰€ä»¥æœŸæœ›å€¼å’ŒçœŸå€¼ä¹‹é—´å¯èƒ½æœ‰åå·®ã€‚
        
    - ä½†å› ä¸ºåªä¾èµ–ä¸€æ­¥çš„é‡‡æ ·ï¼Œéšæœºæ€§å° â†’ **æ–¹å·®ä½**ã€‚
        

---

1. ä¸¾ä¸ªä¾‹å­
    

å‡è®¾çœŸå® Q(s,a)=5ã€‚

- **Monte Carlo**ï¼šè·‘ 3 æ¡è½¨è¿¹ï¼Œå¾—åˆ°å›æŠ¥ï¼š2,10,32
    
    - å¹³å‡å€¼ = 5ï¼ˆæ— åå·®ï¼‰
        
    - æ–¹å·®å¾ˆå¤§ï¼ˆæ•°å€¼æ³¢åŠ¨å¤§ï¼‰ã€‚
        
- **TD**ï¼šä¸€æ­¥é¢„æµ‹ï¼š4.8,5.1,5.2
    
    - å¹³å‡å€¼ â‰ˆ 5.03ï¼Œæœ‰ä¸€ç‚¹ç‚¹åå·®ã€‚
        
    - ä½†æ–¹å·®å¾ˆå°ï¼ˆç»“æœéƒ½æ¥è¿‘ 5ï¼‰
        

3.  Temporal Difference
    

noteï¼š

1. TDé‡Œé¢åº”è¯¥æ˜¯Q(st+1,at+1)ã€‚
    
2. Qtå’ŒQt+1æ˜¯å¦‚ä½•æ¼”å˜çš„
    
    ![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=ZWRhMTY3MTk5Y2FlMWY2NjBlZjQwMzAzZWFlYWJmYzdfRkZLRnJNQXpaUEphNXdrQmN1UjJYdDRhR3dKN2w4aE1fVG9rZW46T29YcGI5bmJJb3NFTkR4a0lFS2wzRFBjZ3hnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)
    
3. æ›´æ–°Qï¼ˆstï¼Œatï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°
    
    1. å°æ±½è½¦ä¸€å¼€å§‹çš„Q(st,at)=30
        
    2. å¼€äº†10åˆ†é’Ÿï¼ˆr(st,at)ï¼‰=10ï¼ŒQ(st+1,at+1) = 18
        
    3. æˆ‘ä»¬å¸Œæœ› $rt+Î³QÏ€(st+1,at+1)âˆ’QÏ€(st,at) = 0$ ï¼Œæ‰€ä»¥æˆ‘ä»¬æ±‚å¯¼ï¼Œç„¶åå¾—åˆ°æ¢¯åº¦ã€‚ç„¶ååŸºäºä¼˜åŒ–å‡½æ•°ï¼ˆæŠŠä»–å½“ä½œadamï¼Œsgdç­‰çœ‹å¾…å°±è¡Œï¼‰ $QÏ€(st,at)â†QÏ€(st,at)+Î±[rt+Î³QÏ€(st+1,at+1)âˆ’QÏ€(st,at)]$, æˆ‘ä»¬çš„æ›´æ–°å…¬å¼ä¸º30 + Î±ï¼ˆ10 + 18 - 30ï¼‰ï¼Œç„¶åå¾—åˆ°çš„å€¼æ¥æ›´æ–°tableã€‚
        
    4. å¦‚æœæ˜¯ç½‘ç»œåˆ™ç”¨æŸå¤±å‡½æ•°æ›´æ–°ï¼Œå¾—åˆ°æ¢¯åº¦çš„æ–¹å¼ä¸ºæœ€å¤§åŒ– $L(\theta) = \Big( r_t + \gamma Q(s_{t+1},a_{t+1};\theta) - Q(s_t,a_t;\theta) \Big)^2$
        

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=ZjJjNmQ2NWRjNzg2OTU4ODQ5YjI0NzE1ZDk4MDQ5M2ZfNmw4TEx4RzJUTDJadGEza0xGMUM0RWRHNGR6SE02cWxfVG9rZW46TTAxY2JUZlhmb05iNU54ZXlHQmx5UUNLZ1ZoXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

```C++
æç®€ä¼ªä»£ç ï¼ˆæ¯æ­¥å­¦ä¹ ï¼‰
init Î¸, Ï†
loop for t = 0,1,2,...:
    observe s_t
    sample a_t ~ Ï€_Î¸(Â·|s_t)
    execute a_t â†’ get r_{t+1}, s_{t+1}

    Î´_t = r_{t+1} + Î³ V_Ï†(s_{t+1}) - V_Ï†(s_t)

    # critic update (one step)
    Ï† â† Ï† + Î±_V * Î´_t * âˆ‡_Ï† V_Ï†(s_t)

    # actor update (one step)
    Î¸ â† Î¸ + Î±_Ï€ * Î´_t * âˆ‡_Î¸ log Ï€_Î¸(a_t | s_t)
    # (+ optional entropy bonus on Î¸)
```

4.  SARSA and Q learningï¼ˆTDï¼‰
    

TDçš„ç®—æ³•æœ‰SARSA and Q learning

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=NzUwMGE5M2EyZTZmOTM4NTEzNGEyOTRmNzJjMDkzYzNfd2MyS0FKNE1JQUhrelBXY3BqY0dMNmtKZ29iV1laYldfVG9rZW46U0E3RGJ3VmU2b2E2TWJ4ZTZlR2xycjlrZ2htXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

1. Sarsa ä¸ºä¸€ä¸ªgreedyç®—æ³•ï¼Œç»™å®šs1ï¼Œç„¶åæ‰¾æœ€å¤§ä»·å€¼çš„aï¼Œå¹¶è¿”è¿˜Qï¼ˆä»·å€¼ï¼Œæ¯”å¦‚å›¾ä¸­çš„23ï¼‰å’Œaï¼Œä½†æ˜¯ä¸ºäº†é˜²æ­¢æ¬¡æ¬¡éƒ½ç®—æœ€å¤§ï¼Œæˆ‘ä»¬ä»¥æ¦‚ç‡Îµé€‰æ‹©å…¶ä»–çš„action
    
    1. å¦‚æœ Îµ=0ï¼Œä¸€å®šé€‰ a1 ï¼ˆgreedyï¼‰
        
    2. æœ Îµ=0.1ï¼Œé‚£ä¹ˆï¼š
        
        1. 90% æ¦‚ç‡é€‰ a1ï¼Œ
            
        2. 10% æ¦‚ç‡åœ¨ {a1,a2,a3}é‡Œéšæœºé€‰ä¸€ä¸ªï¼ˆå¯èƒ½é€‰åˆ° a2 æˆ– a3ï¼‰ã€‚
            
2. ä¸ç®¡æ˜¯DQNè¿˜æ˜¯Tableçš„å½¢å¼ï¼Œæœ¬è´¨éƒ½æ˜¯æŸ¥è¡¨ï¼Œåªä¸è¿‡ç½‘ç»œæ˜¯ä¸€æ¬¡æ€§è¾“å‡ºè¯¥çŠ¶æ€ä¸‹st **æ‰€æœ‰å¯èƒ½åŠ¨ä½œa1,a2,a3, æœ€ç»ˆå¾—åˆ°æ‰€æœ‰çš„**çš„ Q å€¼å‘é‡ï¼Œä¹Ÿå°±æ˜¯discounted returnï¼Œç„¶åæˆ‘ä»¬greedyçš„è·å¾—aï¼Œç„¶åå†é€šè¿‡ç¯å¢ƒè·å¾—r
    
3. **Behavior policy** = ä½ å®é™…åœ¨ç¯å¢ƒé‡Œæ€ä¹ˆé€‰åŠ¨ä½œçš„æ–¹å¼ã€‚
    

**Target policy** = ä½ æ›´æ–°æ—¶å‡è®¾æœªæ¥ä¼šæ€ä¹ˆé€‰åŠ¨ä½œçš„æ–¹å¼ã€‚

4. DQN å·¥ä½œæµç¨‹ï¼š
    
    Â Â DQNä¸ºQå‡½æ•°çš„ç¥ç»ç½‘ç»œç‰ˆæœ¬ï¼ŒSARSAï¼ŒQlearningéƒ½æ˜¯ç”¨tableæ¥åšQå‡½æ•°
    
    2. è¾“å…¥çŠ¶æ€
        
        1. ç¥ç»ç½‘ç»œè¾“å…¥å½“å‰ç¯å¢ƒçš„çŠ¶æ€ stï¼ˆæ¯”å¦‚ä¸€å¼ æ¸¸æˆç”»é¢ï¼‰ã€‚
            
    3. è¾“å‡ºæ‰€æœ‰åŠ¨ä½œçš„ Q å€¼
        
        1. ç½‘ç»œä¸€æ¬¡æ€§è¾“å‡ºè¯¥çŠ¶æ€ä¸‹ **æ‰€æœ‰å¯èƒ½åŠ¨ä½œ** çš„ Q å€¼å‘é‡ï¼š
            
        2. $[Q(s_t,a_1), Q(s_t,a_2), \dots, Q(s_t,a_n)]$
            
        
Â Â Â Â ğŸ“Œ æ³¨æ„ï¼šä¸ç”¨ä¸€ä¸ªä¸€ä¸ªä¼ å…¥ actionï¼Œè€Œæ˜¯ä¸€æ¬¡å‰å‘ä¼ æ’­å°±å¾—åˆ°æ‰€æœ‰åŠ¨ä½œçš„ Q å€¼ã€‚
        
    4. åŠ¨ä½œé€‰æ‹© (Îµ-greedy)
        
        1. ä»¥æ¦‚ç‡ 1âˆ’Îµï¼šé€‰ Q å€¼æœ€å¤§çš„åŠ¨ä½œï¼ˆgreedyï¼‰ã€‚
            
        2. ä»¥æ¦‚ç‡ Îµï¼šéšæœºé€‰ä¸€ä¸ªåŠ¨ä½œï¼ˆæ¢ç´¢ï¼‰ã€‚
            
    5. æ‰§è¡ŒåŠ¨ä½œï¼Œå¾—åˆ°å¥–åŠ±å’Œä¸‹ä¸€ä¸ªçŠ¶æ€
        
        1. æ‰§è¡ŒåŠ¨ä½œ aï¼Œç¯å¢ƒè¿”å›å¥–åŠ± rt å’Œæ–°çŠ¶æ€ st+1ã€‚
            
    6. å­˜å‚¨ç»éªŒ (Replay Buffer)
        
        1. æŠŠè½¬ç§»æ ·æœ¬ (st,at,rt,st+1,done)å­˜å…¥ç»éªŒå›æ”¾æ± ã€‚
            
    7. é‡‡æ ·è®­ç»ƒ
        
        1. ä»å›æ”¾æ± é‡Œéšæœºé‡‡æ ·ä¸€æ‰¹æ•°æ®ï¼Œç”¨æ¥è®­ç»ƒç¥ç»ç½‘ç»œã€‚
            
        2. ç›®æ ‡å€¼ (TD target)ï¼š
            
            - $y_t = r_t + \gamma \max_{a'} Q_{\theta^-}(s_{t+1}, a')$
                
            - ï¼ˆè¿™é‡Œçš„ $Q_{\theta^-}$æ˜¯ target networkï¼‰
                
        3. æŸå¤±å‡½æ•°ï¼š
            
            - $L(\theta) = \frac{1}{2}\big(y_t - Q_\theta(s_t,a_t)\big)^2$or $L(\theta) = \Big( r_t + \gamma Q(s_{t+1},a_{t+1};\theta) - Q(s_t,a_t;\theta) \Big)^2$
                
    8. æ›´æ–°å‚æ•°
        
        1. ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°ç¥ç»ç½‘ç»œå‚æ•° Î¸ã€‚
            

4.  On policy and Off policy
    

å¦‚æœbehaviorå’Œtarget policyæ˜¯ä¸€æ ·çš„æ–¹æ³•ï¼Œæ¯”å¦‚SARSAï¼Œé‚£ä¹ˆå°±æ˜¯on policyï¼Œå¦‚æœä¸ä¸€æ ·é‚£ä¹ˆå°±æ˜¯off policy

  

  

1. On policyçš„æœ¬è´¨å°±æ˜¯Î æ˜¯ä¸æ˜¯æ–°çš„Î ï¼Œä¼šä¸ä¼šäº§ç”Ÿæ–°çš„ä¸åŒåˆ†å¸ƒçš„a
    
    ![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=YWE3ODFkNDg1ZDkwMDYwMDZiOWI1ZDIyMjQyYmE4YmVfSmJTZFJ6cVZOVjlpQ0U4T0pjRktQY0d1dnJISzh5UEpfVG9rZW46VHdpQ2JKQkVBb1pTd3p4TWVKN2xuTlRIZ0toXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)
    
    2. ä»¥SARSAä¸ºä¾‹ï¼š
        
        1. æˆ‘ä»¬é¦–å…ˆé‡‡æ ·Nä¸ªst,at,rt,st+1
            
        2. ä»¥ä¸Šé¢çš„å…¬å¼ä¸ºä¾‹å­ï¼Œå…¶ä¸­åœ¨æ›´æ–°Qçš„è¿‡ç¨‹ä¸­ï¼Œå³è¾¹çš„Q(st,at)å’ŒQ(st+1,at+1)çš„å‚æ•°éƒ½æ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥action açš„åˆ†å¸ƒæ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥ä¸éœ€è¦é‡è¦æ€§é‡‡æ ·ï¼Œå¹¶ä¸”ç”¨çš„å°±æ˜¯è€æ•°æ®æ›´æ–°çš„ã€‚
            
        3. è¿™é‡Œä¸€ç›´å†»ç»“QÎ¸ç›´åˆ°æ‰€æœ‰Næ›´æ–°å®Œï¼Œè¿™é‡Œå¯ä»¥æ˜¯ä¸€æ¬¡æ€§ç›´æ¥å…¨éƒ¨æ›´æ–°å®Œï¼Œæˆ–è€…mini batchéƒ½è¡Œ
            
        4. æœ€ç»ˆæ›´æ–°Q
            
        
        Â Â Â Â æ€»ç»“ï¼šå’Œcriticä¸ä¸€æ ·çš„æ˜¯ï¼Œè¿™é‡Œæ˜¯å‚æ•°å†»ç»“çš„æƒ…å†µä¸‹ï¼Œæ›´æ–°å®ŒNä¸ªdata point
        
    3. ä»¥Q learning ä¸ºä¾‹
        
        ![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=NmEyNGE4NmY1ZTY5NzdkMTE4YWI4YWM0NTllYzlkMDRfdndTbVJmUFlqU055bTVlM0JQa0o0eWdGWXVpVm4ydElfVG9rZW46RUhBMmJKajVCbzUwUmJ4UWxkeWxOeldOZ3BiXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)
        
        ![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=ODhkNWE1NmJhZjk0MmRlOGJmMDliNzEwMDE2MWQxZWRfa1pNRVRUaXNPNWRFUVRqcEprMzlWQ2hUQmdPYlJ2RnBfVG9rZW46WkphbWJxMGNOb2hyRlR4NzBNb2xNYzdqZ3BjXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)
        
        3. æˆ‘ä»¬é¦–å…ˆç”¨behavioré‡‡æ ·Nä¸ªst,at,rt,st+1, target behaviorä¹Ÿå¯ä»¥å»é‡‡æ ·ä¸€äº›ç‚¹ã€‚è¿™é‡Œçš„policy Î æ˜¯ä¸ä¸€æ ·çš„ï¼Œæ‰€ä»¥å¯ä»¥åˆ†å¼€é‡‡æ ·ã€‚ç›¸å½“äºbehaviorç”¨äº†ä¸€ä¸ªç½‘ç»œï¼ˆrandomï¼‰ï¼Œæˆ–è€…tableæ¥è¿›è¡Œé‡‡æ ·ç„¶åè·å¾—æ•°æ®ï¼Œtargetä¹Ÿæ˜¯ä¸€æ ·ï¼Œåªä¸è¿‡ä»–ä»¬ç”¨çš„ç½‘ç»œæˆ–è€…tableä¸ä¸€æ ·ã€‚è™½ç„¶Q learningç”¨çš„è¿˜æ˜¯ä¹‹å‰çš„Qçš„tableæˆ–è€…ç½‘ç»œï¼Œä½†æ˜¯æœ€ç»ˆçš„å†³ç­–è¿‡ç¨‹Î æ˜¯greedy ä¸æ˜¯randomã€‚æ¯”å¦‚ï¼ŒQ(st,at)å’ŒQ(st+1,at+1)çš„å†³ç­–æ–¹æ³•æ˜¯ä¸ä¸€æ ·çš„ï¼Œå› ä¸ºä¸€ä¸ªç”¨max ï¼ˆgreedyï¼‰ä¸€ä¸ªrandomï¼Œç­–ç•¥ä¸åŒï¼Œæ‰€ä»¥ä¼šç›´åˆ°åç»­çš„é‡‡æ ·æ•°æ®æ˜¯ä¸ä¸€æ ·çš„ï¼Œæ¯”å¦‚æ•°æ®aï¼Œst+1, at+1...sTåˆ†å¸ƒæ˜¯ä¸ä¸€æ ·çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è¯´ä¸¤è€…behavioræ•°æ®åˆ†å¸ƒä¸åŒï¼Œé‚£ä¹ˆå°±æ˜¯off policy
            
    4. PPOä¸ºä¾‹ï¼ˆonpolicyï¼‰
		PPOæ˜¯ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆåƒoff-policyï¼ˆå› ä¸ºä»–æ˜¯å¤åˆ¶äº†è€çš„ï¼Œç„¶åæ›´æ–°ï¼Œè¿‡ç¨‹ä¸­ä¼šå‡ºç°ä¸¤ä¸ªÎ ï¼‰çš„on-policyç®—æ³•ï¼ˆ**PPO è¦â€œæ–°é‡‡æ ·â†’åœ¨è¿™æ‰¹ä¸Šè®­ç»ƒâ†’ä¸¢å¼ƒâ€ï¼Œä¸èƒ½åƒ off-policy é‚£æ ·é•¿æœŸåƒæ—§/å¼‚ç­–ç•¥æ•°æ®ï¼Œè¿™æ‰æ˜¯å®ƒ on-policy çš„æœ¬è´¨**ï¼‰ã€‚â€œä¸¢ä¸ä¸¢å¼ƒæ•°æ®â€åªæ˜¯**ç°è±¡**è€Œä¸æ˜¯å®šä¹‰ï¼š**on-policy**è¦æ±‚ç”¨ä¸ç›®æ ‡ç­–ç•¥ï¼ˆå½“å‰/åˆšå†»ç»“çš„ç­–ç•¥ï¼‰**ä¸€è‡´æˆ–è¿‘é‚»**åˆ†å¸ƒçš„æ•°æ®è®­ç»ƒï¼ˆæ‰€ä»¥æ—§æ•°æ®å¸¸è¢«ä¸¢å¼ƒä»¥é¿å…åˆ†å¸ƒæ¼‚ç§»ï¼‰ï¼›**off-policy**åˆ™èƒ½åœ¨**è¡Œä¸ºâ‰ ç›®æ ‡**æ—¶ä¾ç„¶æœ‰æ•ˆå­¦ä¹ ï¼ˆé æœ€ä¼˜/è½¯æœ€ä¼˜å¤‡ä»½å¦‚ `max`ï¼Œæˆ– IS/æˆªæ–­-IS ç­‰çº åï¼‰ï¼Œå› æ­¤å¯ä»¥é•¿æœŸå¤ç”¨å›æ”¾æ•°æ®ã€‚
        

  

2.  Policy basedï¼šPolicy Gradient
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=OWViYmVhNDIxNTM3NzAxNmQyYThlMGYyYzJiYTlkNzZfWW1pMDI1SzBDWnliT2tVSmpDT09hd0NKYWk4WTZyOWVfVG9rZW46SlhDWmJZSjY5b1dzeFV4c2tIemxjZ2RzZ1RkXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

1. æˆ‘ä»¬å¸Œæœ›å½“å‰så‡ºç°åŠ¨ä½œaçš„æ¦‚ç‡å¢é«˜ï¼Œç„¶åQ(s,a)çš„ä»·å€¼æœ€å¤§
2. ç›®æ ‡å‡½æ•° J(Î¸)ï¼ˆå¯¹æ‰€æœ‰è½¨è¿¹æ±‚å’Œï¼‰
	- è®¾ä¸€æ¡è½¨è¿¹ $Ï„=(s0,a0,r0,â€¦,sT)$ï¼Œå®ƒçš„ç´¯è®¡å›æŠ¥$R(\tau)=\sum_{t=0}^{T-1}\gamma^t r_t$ 
	- è½¨è¿¹åœ¨ç­–ç•¥ Ï€Î¸ ä¸‹å‡ºç°çš„æ¦‚ç‡
	- $p_\theta(\tau)=\rho(s_0)\prod_{t=0}^{T-1}\pi_\theta(a_t|s_t)\,P(s_{t+1}|s_t,a_t)$
	- ï¼ˆåˆå§‹åˆ†å¸ƒ Ï å’Œç¯å¢ƒè½¬ç§» P ä¸ Î¸ æ— å…³ï¼‰ã€‚
	- äºæ˜¯ $J(\theta)=\sum_{\tau} p_\theta(\tau)\,R(\tau)$

3.  Reinforce and ACtor Critic
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=ODQ5Njc5ZGM5ODFiOGY4YjAzMWYwNDM1MjM0MWY1NWVfUGxjUTl3Mlk1RUV4RVpPbzFLNDZhVUJYOHkzZDg2aHpfVG9rZW46UDJWbmJUOFFCb1RvTWd4OVNjNmxuQUJYZ3hnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

1. å·¦ä¸Šè§’å¦‚ä½•æ±‚è§£Qæ˜¯ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨
    
    1. Actor critic å¾—åˆ°ä¸€ä¸ªQçš„ç½‘ç»œï¼Œæˆ–è€…table
        
    2. reinforceï¼Œå°±æ˜¯ç›´æ¥æŠŠæ‰€æœ‰çš„råŠ èµ·æ¥ï¼Œä½†æ˜¯å®ƒåšä¸åˆ°ä¸­é€”è®­ç»ƒï¼Œ**å®Œæ•´ä¸€æ¡è½¨è¿¹ episode ç»“æŸ**ï¼Œæ‰èƒ½ç®—æ¯ä¸ªæ—¶åˆ»çš„å›æŠ¥ Gt
        
    3. baselineå°±æ˜¯æå®æ¯…actor criticçš„æ–¹å¼
        

2.  The problem of policy Gradient
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=YTNiZGYyODlkZjg3NDZlMzdiM2ZkMTVlOWMzNzA0NmJfM1p0N2lqeE1ZbVlwSXJadmJrcUlteXlXSTBWQzhHczdfVG9rZW46VFRHc2JsUEc3bzlpMjV4YjAwMWw5SW1MZ0xmXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

æˆ‘ä»¬ä¸å¸Œæœ›å‚æ•°ä¸€æ¬¡æ€§æ›´æ–°çš„å¤ªå¤§ï¼Œæ‰€ä»¥æˆ‘ä»¬å¸Œæœ›å‚æ•°æ›´æ–°çš„å€¼å°äºä¸€ä¸ªé˜ˆå€¼

1.  Important sampling
    

æˆ‘ä»¬æœ‰p(x),f(x), æˆ‘ä»¬æƒ³è¦å–ä»p(x)é‡‡æ ·å¾ˆå›°éš¾çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥ä¸€ä¸ªq(x)ç„¶åï¼Œç„¶åå¯¹xæ±‚ç§¯åˆ†ã€‚

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=OGIwN2JhOTNmYzBmYjdiY2U3NGUyM2IxM2JmMDNlMzdfNDhBa2ppc01kSE1jcldVdlFsbFJxQk05MWRUM1g0eUVfVG9rZW46Szd1YmIxWGVqb0pZb2N4VjdGZ2xuRjh6Z0pjXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

æ„æ€å°±æ˜¯å¤šæ¬¡é‡‡æ ·ä¹‹åï¼Œå¾—åˆ°çš„å¹³å‡å€¼å°±æ˜¯p(x)çš„æ¦‚ç‡å¯†åº¦å‡½æ•°çš„æƒ…å†µä¸‹f(x)çš„æœŸæœ›/å¹³å‡å€¼ã€‚

ç°åœ¨æˆ‘ä»¬æ€è€ƒå¦‚ä½•æ‰èƒ½åº”ç”¨åˆ°RLä¸­ã€‚

1. æˆ‘ä»¬è·å–åˆ°äº†ä¸€å †st,at,rt,st+1 * Nï¼Œå¹¶æœ€ç»ˆè®¡ç®—A_old
    
2. æˆ‘ä»¬å¼€å§‹æ›´æ–°policy Î _old å¾—åˆ°Î _newï¼Œé‚£ä¹ˆÎ _newå°±æ˜¯æ–°çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬åˆä¸æƒ³é‡æ–°è®¡ç®—A_newï¼Œå¦‚ä½•æ‰èƒ½ç»§ç»­ä½¿ç”¨A_oldå‘¢ï¼Ÿ
    
3. æˆ‘ä»¬æŠŠA_oldå½“ä½œf(x)ï¼Œp(x)å½“ä½œÎ _newï¼Œæˆ‘ä»¬ä»è€Î _old é‡‡æ ·å¾—åˆ°çš„æ•°æ®æ˜¯ä¸æ˜¯å°±å¯ä»¥ç”¨äº†ï¼Ÿ
    
4. æ‰€ä»¥æœ€ç»ˆæˆ‘ä»¬ä¼šä½¿ç”¨ Î _new/Î _old çš„å½¢å¼æ¥è¡¨ç¤ºp(x)/q(x)
    

  

æ€è€ƒï¼š

1. # ä¸ºä»€ä¹ˆQ learningä¸ç”¨è¿™ä¸ªï¼Ÿï¼ˆè¯´å®è¯æ²¡ææ‡‚è¿™ä¸ªï¼‰https://zhuanlan.zhihu.com/p/346433931
    
    1. ç›´è§‰ä¸Šæƒ³ç€ï¼Œæˆ‘é€šè¿‡ä¸åŒçš„policyé‡‡æ ·ï¼Œé‚£ä¹ˆæˆ‘çš„Qå€¼ä¹Ÿæ˜¯ä¸ä¸€æ ·çš„å‘€ï¼Œè¿™æ ·ä¸ä¼šå½±å“å…¶åœ¨æ›´æ–°æ—¶çš„åˆ†å¸ƒå—ï¼Ÿ $Q_t - (r + Q_{t+1})$æ¯”å¦‚Vt+1å¾ˆå¤§ï¼ŒVtå¾ˆå°ï¼Œæˆ‘ä»¬è®©ä»–ä»¬åˆ†å¸ƒä¸€æ ·ä¸å¥½å—ï¼Ÿç­”æ¡ˆæ˜¯åŒåˆ†å¸ƒâ€æ²¡æ„ä¹‰ï¼Œç”šè‡³æœ‰å®³ã€‚**Bellman ä¸åŠ¨ç‚¹ä¼šè¢«æ”¹å†™**ï¼šå¦‚æœä½ å¯¹ Qt æˆ– yt æ–½åŠ ä¸æ ·æœ¬ç›¸å…³çš„éçº¿æ€§â€œå½’ä¸€åŒ–â€ï¼Œå°±ç›¸å½“äºæ”¹äº†ç›®æ ‡å‡½æ•°ï¼Œå¯èƒ½ä¸å†æ”¶æ•›åˆ° Q
        
    
    Â Â $\mathbb{E}_{(s,a)\sim d_\mu}\big[\big(y(s,a)-Q_\theta(s,a)\big)^2\big], \quad y=r+\gamma \max_{a'}Q_{\bar\theta}(s',a')$
    

2.  Trust region policy optimization(ç»†èŠ‚è¿˜æ²¡æœ‰ç ”ç©¶)
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=Nzk1YmJkN2RiZjYzM2U3MGYxNmNiZjI3MTE1NzAzZjJfSVdYaUo4MzU5QTU5RFEwOENUeVdoNU1JUjhiOW5USjJfVG9rZW46WjF1eWJpdThub2MyRHB4TWdCd2xPYzd2Z0lkXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

Delve in ç ”ç©¶

å‡è®¾æˆ‘ä»¬é‡‡æ ·äº† N æ¡è½¨è¿¹ï¼Œæ¯æ¡è½¨è¿¹é•¿åº¦ Tiã€‚é‚£ä¹ˆæœŸæœ›å°±å¯ä»¥è¿‘ä¼¼ä¸ºï¼š

$J(\theta') - J(\theta) \;\approx\; \frac{1}{N} \sum_{i=1}^{N} \;\sum_{t=0}^{T_i-1} \Bigg[ \frac{\pi_{\theta'}(a_t^{(i)} \mid s_t^{(i)})}{\pi_\theta(a_t^{(i)} \mid s_t^{(i)})} \;\gamma^t \; A_{\pi_\theta}(s_t^{(i)},a_t^{(i)}) \Bigg]$

æ³¨æ„ï¼š

1. ä¸ºä»€ä¹ˆä½¿ç”¨äº†é‡è¦æ€§é‡‡æ ·ä¹‹åï¼Œå¼å­æ„Ÿè§‰å°‘äº†ä¸€ä¸ªÎ Î¸ï¼Ÿä¹Ÿå°±æ˜¯è€çš„ç­–ç•¥
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=OTkwOTkyOGQyMGY2NGMxZGM1MGRkY2Y1NjEwZDMwMGNfT0o4d3FpVnpJdU9UQkhtR3JyaE9VeFZPT3JYZ0F2NUhfVG9rZW46RjBSeWJLOTd2bzhRUG94SGFsNGxCNHFWZ1plXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

å› ä¸ºè¿™ä¸ªæ±‚å’Œæ˜¯ä»¥æ•°æ®ç»´åº¦æ±‚å’Œï¼Œæ•°æ®ä¸ºä¸€å †st,at,r,st+1ï¼Œå¹¶ä¸”è¿™äº›æ•°æ®å·²ç»æ˜¯Î Î¸çš„æ¦‚ç‡çš„åˆ†å¸ƒäº†ï¼Œæ‰€ä»¥ä¸éœ€è¦ä¹˜Î Î¸

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=ZTkzMDMzZDE5MjcwY2JmZTBlYjMyZjg4OWFkYzUyY2NfckZ4MDBRSUNXSzhHUlY3YUFCazd1U01uem9Jd2pyRVdfVG9rZW46QlpkQmJJM1pjb3RkNW94QTRvYWwzcGNKZzJnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

Â Â Aè¿™ä¸ªéƒ¨åˆ†ä¸ºç›´æ¥æŠŠæœŸæœ›å†™æˆå…¬å¼çš„å½¢å¼ï¼Œä¸‹é¢ä¸ºç­‰ä»·è½¬æ¢çš„å½¢å¼ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬å…¬å¼ä¸­ä½¿ç”¨ç»™çš„å½¢å¼ã€‚

7.  PPO
    

  

8.  å…¬å¼
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=MTEwMTFlNTI2NTczNTc2Njg5MTFhMjc2MmU0OGYzM2VfNWdMTkFyMUdWeUZROTM5cEVWTU9LZEFndjJvdURZMWhfVG9rZW46UWdJUGI5VXRmb3ZwbTR4TXducGxMV1A5Z0tiXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

1. éæœŸæœ›å½¢å¼
    
    1. PPO-penalty
        
    
    Â Â $\begin{equation} L^{\text{PPO-penalty}}(\theta') \approx \frac{1}{N}\sum_{i=1}^N \sum_{t=0}^{T_i-1} \left[ \frac{\pi_{\theta'}(a_t^{(i)} \mid s_t^{(i)})}{\pi_{\theta}(a_t^{(i)} \mid s_t^{(i)})} \, \hat{A}_t^{(i)} - \beta \, D_{\text{KL}}\!\Big(\pi_{\theta}(\cdot \mid s_t^{(i)}) \,\|\, \pi_{\theta'}(\cdot \mid s_t^{(i)})\Big) \right] \end{equation}$
    
    2. PPO-clip
        
        Â Â Â Â $\begin{equation} L^{\text{PPO-clip}}(\theta') \approx \frac{1}{N}\sum_{i=1}^N \sum_{t=0}^{T_i-1} \min\!\Bigg( \frac{\pi_{\theta'}(a_t^{(i)} \mid s_t^{(i)})}{\pi_{\theta}(a_t^{(i)} \mid s_t^{(i)})} \, \hat{A}_t^{(i)}, \; \text{clip}\!\left( \frac{\pi_{\theta'}(a_t^{(i)} \mid s_t^{(i)})}{\pi_{\theta}(a_t^{(i)} \mid s_t^{(i)})}, \, 1-\epsilon, \, 1+\epsilon \right)\hat{A}_t^{(i)} \Bigg) \end{equation}$
        
    3. æˆ‘ä»¬ç›®æ ‡å°±æ˜¯è®©è¿™ä¿©Læœ€å¤§
        
2. è¿™é‡Œçš„A_hatå°±æ˜¯GAE
    
3. penalty
    
    1. å¦‚æœklå°äºé˜ˆå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¸Œæœ›å¤šæ›´æ–°ï¼Œæ‰€ä»¥å‡å°‘æƒ©ç½š
        
    2. å¦‚æœkl>é˜ˆå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¸Œæœ›å°‘æ›´æ–°ï¼Œæ‰€ä»¥å¢åŠ æƒ©ç½š
        
    
    Â Â PPO-penalty åŠ¨æ€è°ƒèŠ‚ Î² çš„ç›®çš„ = æ§åˆ¶è®­ç»ƒçš„å¹³ç¨³æ€§ï¼Œå‡å°‘éœ‡è¡ã€‚å¼ºåŒ–å­¦ä¹ é‡Œéå¸¸é‡è¦çš„ **ç¨³å®šæ€§ä¼˜å…ˆ** åŸåˆ™ï¼šæ¯”èµ·å­¦å¾—å¿«ï¼Œæ›´æ€•å­¦åã€‚
    
4. Clip
    
    1. å¦‚æœè¶…å‡ºäº†ä¸€ä¸ªèŒƒå›´å°±ç›´æ¥æˆªæ–­ï¼Œä¹Ÿæ˜¯ä¸ºäº†ç¨³å®šæ€§
        

5.  è®­ç»ƒ
    

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=Zjc1NWQ3ZWQ1MDBiZTFkMWY2N2U3ZTAwYjU5YmU5YjVfZWM2ZnFrV3p1S0xWMHZDcm1Wekk5VjVHaHNUMmNYVFNfVG9rZW46REJ5UmJPR050b052V1d4enBqTGxOOWxlZ3ZoXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

1. æ•°æ®å‡†å¤‡ï¼Œpolicyç½‘ç»œï¼Œvalueç½‘ç»œ
    
    ![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=NmRkMGU3YThmZDJlM2QxZjM2ZjQ0NGI3OWQ2MWY4M2RfajRDRHpwVmNkeGZ6N3NLRkJ3OVhiZDc5V1FVWUFUdlVfVG9rZW46QWFPMGJ1Tno2b1BxTTR4cllnQ2xtQ095Z3FnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=NzY5NjdhYjdmZmM2ZmU4OTUwOWZiOTEzYTBiY2QxYzBfSWJ6UHpIek4yQmdHNXc4WHdLTE5zbFlSMllPdGdaZGFfVG9rZW46VHVXUGJ0em1hb21SNTh4cVNnUWxpU2trZ2ZnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=ZjU5OTFiMDg3Y2ViYjgzYjVjOGNiZmI4MDc2YjVhZWRfbXhTRUdZUFJ2OXVpaFNlVWJ0QVU5U3dkREw5MHNoU1pfVG9rZW46WmlwUGJjdlNYb1pOQVN4OG9ScWxaVlBEZzhiXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)
    
    3. æ”¶é›†æ•°æ®ï¼ˆä½¿ç”¨æ—§ç­–ç•¥ï¼‰åœ¨å½“å‰ç­–ç•¥å‚æ•° Î¸ä¸‹ï¼Œè·‘ç¯å¢ƒï¼Œæ”¶é›†ä¸€æ‰¹è½¨è¿¹ï¼š (st,at,rt,st+1)ã€‚
        
    4. ç”¨è¿™äº›æ•°æ®ç”¨VÎ¸ä¼°è®¡ **ä¼˜åŠ¿å‡½æ•°** $\hat{A}_t$ï¼ˆæ¯”å¦‚ç”¨ GAEï¼‰ã€‚
        
        ![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=OWZlNzQ5ODk1NzIzNDk5MjYwZWJjNjU5N2NjOWJmN2Nfc2FOSk9SVzNNbVhSUGdMWXhDNmlvNkg5T2pxd3NkQmdfVG9rZW46TWFJdWJDN0E5b2NINml4dGR4TmxKVlNrZzBlXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)
        
        ![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=YTU1NTJlM2JhNmVhYzE0MTZlNjZiMDJhMWI2OTMxMjFfV2tKclkyS2VMU1VEblFCSUN0TTF1WHlnbm1FOU10bDhfVG9rZW46QXVvTWJtRUZKb3RXR3N4dmxSUWxXbmhVZ3pnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)
        
    5. è¿™é‡Œçš„ç­–ç•¥å°±æ˜¯ **æ—§ç­–ç•¥** Ï€Î¸ã€‚è¿™ä¸€æ­¥çš„ä½œç”¨ï¼šç”Ÿæˆæ ·æœ¬ï¼Œå›ºå®šä¸‹æ¥ï¼Œæ¥ä¸‹æ¥è®­ç»ƒæ—¶ä¸å†æ›´æ–°å®ƒã€‚
        
2. è®¡ç®—æ¯”ç‡ï¼ˆæ–°/è€ç­–ç•¥ï¼‰
    
    Â Â ä¼˜åŒ–æ—¶ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªæ–°çš„å‚æ•° Î¸â€²ï¼ˆè®­ç»ƒæ—¶ä¼šé€æ¸æ›´æ–°ï¼‰ã€‚
    
    Â Â  å¯¹æ¯ä¸ªæ ·æœ¬è®¡ç®—ï¼š
    
    Â Â $r_t(\theta') \;=\; \frac{\pi_{\theta'}(a_t|s_t)}{\pi_{\theta}(a_t|s_t)}$
    
    4. åˆ†å­ï¼š**æ–°ç­–ç•¥** Ï€Î¸â€² å¯¹æ ·æœ¬çš„æ¦‚ç‡ï¼ˆéšç€è®­ç»ƒæ›´æ–°ï¼‰ã€‚
        
    5. åˆ†æ¯ï¼š**æ—§ç­–ç•¥** Ï€Î¸ å¯¹æ ·æœ¬çš„æ¦‚ç‡ï¼ˆå›ºå®šä¸å˜ï¼‰ã€‚
        
    6. å¦‚æœ >1ï¼Œè¯´æ˜æ–°ç­–ç•¥æ›´å€¾å‘äºè¿™ä¸ªåŠ¨ä½œï¼›
        
    7. å¦‚æœ <1ï¼Œè¯´æ˜æ–°ç­–ç•¥æ›´ä¸å€¾å‘äºè¿™ä¸ªåŠ¨ä½œã€‚
        
    8. è¿™æ ·åšçš„åŸå› ï¼šè™½ç„¶æ ·æœ¬æ˜¯ç”¨æ—§ç­–ç•¥ç”Ÿæˆçš„ï¼Œä½†æˆ‘ä»¬å¸Œæœ›è¯„ä¼°å¦‚æœæ¢æˆæ–°ç­–ç•¥ï¼Œå®ƒçš„è¡¨ç°å¦‚ä½•ã€‚è¿™ä¸ªæ¯”ç‡å°±æ˜¯ **é‡è¦æ€§é‡‡æ · (importance sampling)**ã€‚
        
3. æ„é€  PPO-clip çš„ç›®æ ‡
    
    1. PPO-penalty or PPO-clip ï¼ˆæœ€å¤§åŒ–ä»·å€¼ï¼‰
        
        Â Â Â Â $\begin{equation} L^{\text{PPO-penalty}}(\theta') \approx \frac{1}{N}\sum_{i=1}^N \sum_{t=0}^{T_i-1} \left[ \frac{\pi_{\theta'}(a_t^{(i)} \mid s_t^{(i)})}{\pi_{\theta}(a_t^{(i)} \mid s_t^{(i)})} \, \hat{A}_t^{(i)} - \beta \, D_{\text{KL}}\!\Big(\pi_{\theta}(\cdot \mid s_t^{(i)}) \,\|\, \pi_{\theta'}(\cdot \mid s_t^{(i)})\Big) \right] \end{equation}$$\begin{equation} L^{\text{PPO-clip}}(\theta') \approx \frac{1}{N}\sum_{i=1}^N \sum_{t=0}^{T_i-1} \min\!\Bigg( \frac{\pi_{\theta'}(a_t^{(i)} \mid s_t^{(i)})}{\pi_{\theta}(a_t^{(i)} \mid s_t^{(i)})} \, \hat{A}_t^{(i)}, \; \text{clip}\!\left( \frac{\pi_{\theta'}(a_t^{(i)} \mid s_t^{(i)})}{\pi_{\theta}(a_t^{(i)} \mid s_t^{(i)})}, \, 1-\epsilon, \, 1+\epsilon \right)\hat{A}_t^{(i)} \Bigg) \end{equation}$
        
        Â Â Â Â æˆ‘ä»¬ç›®æ ‡å°±æ˜¯è®©è¿™ä¿©Læœ€å¤§
        
    2. Value ç›®æ ‡ï¼ˆæœ€å°åŒ–è¯¯å·®ï¼‰
        
        Â Â Â Â $y_t =\hat R_t = \hat A_t + V_{\phi_{\text{old}}}(s_t) \;\;\approx\; Q(s_t,a_t)$
        
        Â Â Â Â ç„¶åè®© VÎ¸(st) å»å›å½’è¿™ä¸ªç›®æ ‡ï¼š
        
        Â Â Â Â $L_{(\theta)} = \frac{1}{N}\sum_t \big(V_\theta(s_t) - y_t\big)^2$
        
        Â Â Â Â note: å’ŒValue basedï¼šMC & TDä¸­æ›´æ–°Qçš„æ–¹å¼æ˜¯ä¸€æ ·çš„
        
    3. âˆ’c2â€‰Entropy(Ï€Î¸)ç†µæ­£åˆ™é¡¹
        
        Â Â Â Â $H(\pi_\theta(\cdot|s_t)) = -\sum_a \pi_\theta(a|s_t) \,\log \pi_\theta(a|s_t)$
        
        2. ç­–ç•¥çš„ç†µå®šä¹‰ä¸ºï¼š
            
        
        Â Â Â Â $H(\pi_\theta(\cdot|s)) = -\sum_a \pi_\theta(a|s) \log \pi_\theta(a|s)$
        
        3. ç†µè¶Šå¤§ï¼Œç­–ç•¥è¶Šéšæœºï¼›ç†µè¶Šå°ï¼Œç­–ç•¥è¶Šç¡®å®šï¼ˆè´ªå¿ƒï¼‰ã€‚
            
        4. æˆ‘ä»¬å¸Œæœ›åœ¨è®­ç»ƒåˆæœŸ**é¼“åŠ±æ¢ç´¢**ï¼Œè®©ç­–ç•¥ä¸è¦å¤ªå¿«å˜å¾—ç¡®å®šï¼Œæ‰€ä»¥è¦**æœ€å¤§åŒ–ç†µ**ã€‚
            
        5. å› ä¸ºæ•´ä½“æ˜¯æœ€å°åŒ–é—®é¢˜ï¼Œæ‰€ä»¥å†™æˆ âˆ’c2â€‰Entropyã€‚
            
    4. å®é™…
        
        1. åœ¨ä¸€ä¸ª epoch çš„ mini-batch é‡Œï¼Œloss ä¸€èˆ¬å†™æˆï¼š
            
            1. æœŸæœ›
                
            
            Â Â Â Â Â Â $\begin{aligned} L(\theta,\phi) &= \mathbb{E}_t \Bigg[ \underbrace{-\min\Bigg( r_t(\theta)\,\hat{A}_t, \; \text{clip}\!\big(r_t(\theta),\, 1-\epsilon,\, 1+\epsilon\big)\,\hat{A}_t \Bigg)}_{\text{Policy Loss (Actor)}} \\ &\quad\quad + \; \underbrace{c_1 \big( V_\phi(s_t) - \hat R_t \big)^2}_{\text{Value Loss (Critic)}} \; - \; \underbrace{c_2 \, H\!\big(\pi_\theta(\cdot|s_t)\big)}_{\text{Entropy Bonus}} \Bigg] \end{aligned}$
            
            2. Batch å½¢å¼
                
                Â Â Â Â Â Â Â Â è®¾ä¸€ä¸ªè®­ç»ƒæ‰¹æ¬¡åŒ…å«è‹¥å¹²æ¡åºåˆ—ï¼Œç”¨ç´¢å¼•é›†åˆ M={(i,t)}è¡¨ç¤ºæœ¬æ¬¡ç”¨äºä¼˜åŒ–çš„æ‰€æœ‰æ ·æœ¬ï¼ˆç¬¬ i æ¡è½¨è¿¹åœ¨æ—¶åˆ» t çš„ä¸€æ¡æ ·æœ¬ï¼‰ã€‚PPO çš„**è¦æœ€å°åŒ–**çš„æ€»æŸå¤±ï¼š
                
                Â Â Â Â Â Â Â Â $\boxed{ L(\theta,\phi) = \frac{1}{|\mathcal{M}|}\sum_{(i,t)\in\mathcal{M}} \Big[ -\min\!\big(\, r_{i,t}(\theta)\,\hat A_{i,t},\ \text{clip}(r_{i,t}(\theta),\,1-\epsilon,\,1+\epsilon)\,\hat A_{i,t}\big) \;+\; c_1\,(V_\phi(s_{i,t})-\hat R_{i,t})^2 \;-\; c_2\,H(\pi_\theta(\cdot|s_{i,t})) \Big] }$
                
        2. å„éƒ¨åˆ†å®šä¹‰
            
            1. ç­–ç•¥æ¯”ç‡
                
            
            Â Â Â Â Â Â $r_{i,t}(\theta) = \frac{\pi_\theta(a_{i,t}|s_{i,t})}{\pi_{\text{old}}(a_{i,t}|s_{i,t})}$
            
            1. ä¼˜åŠ¿ $\hat A_{i,t}$ï¼ˆGAE çš„å±•å¼€/é€’æ¨ï¼Œå‡ä¸ºæœ‰é™å’Œï¼‰
                
                Â Â Â Â Â Â Â Â å…ˆå®šä¹‰ä¸€æ­¥ TD æ®‹å·®ï¼ˆå¸¦ç»ˆæ­¢é®ç½©ï¼‰ï¼š
                
                Â Â Â Â Â Â Â Â $ \delta_{i,t} \;=\; r_{i,t} + \gamma(1-\text{done}_{i,t+1})\,V_\phi(s_{i,t+1}) \;-\; V_\phi(s_{i,t})$
                
            
            Â Â Â Â Â Â å‘åé€’æ¨è®¡ç®— GAEï¼š
            
            Â Â Â Â Â Â Â Â $\hat A_{i,T_i-1} \;=\; \delta_{i,T_i-1}, \quad \hat A_{i,t} \;=\; \delta_{i,t} + \gamma\lambda(1-\text{done}_{i,t+1})\,\hat A_{i,t+1}$
            
            Â Â Â Â Â Â æˆ–å†™æˆæœ‰é™é¡¹æ˜¾å¼æ±‚å’Œï¼š
            
            Â Â Â Â Â Â $\hat A_{i,t} \;=\; \sum_{l=0}^{T_i-t-1} (\gamma\lambda)^l \left[\, r_{i,t+l} + \gamma(1-\text{done}_{i,t+l+1})\,V_\phi(s_{i,t+l+1}) - V_\phi(s_{i,t+l}) \right]$
            
            2. å›æŠ¥ä¼°è®¡
                
            
            Â Â Â Â Â Â $\hat{R}_{i,t} = \hat{A}_{i,t} + V_\phi(s_{i,t})$
            
            3. ç†µæ­£åˆ™é¡¹
                
            
            Â Â Â Â Â Â $H(\pi_\theta(\cdot|s_{i,t})) = -\sum_a \pi_\theta(a|s_{i,t}) \,\log \pi_\theta(a|s_{i,t})$
            
            4. è¶…å‚æ•°
                
                1. Ïµï¼šclip èŒƒå›´ï¼ˆå¦‚ 0.1 æˆ– 0.2ï¼‰ã€‚
                    
                2. c1ï¼švalue loss çš„æƒé‡ã€‚
                    
                3. c2ï¼šç†µé¡¹çš„æƒé‡ã€‚
                    
                4. Î³ï¼šæŠ˜æ‰£å› å­ã€‚
                    
                5. Î»ï¼šGAE è¡°å‡å‚æ•°ã€‚
                    
4. ä¼˜åŒ–ä¸æ›´æ–°
    
    1. **æ”¶é›†æ•°æ®**ï¼ˆç”¨å†»ç»“çš„ $\pi_{\text{old}}$ï¼‰å¾—åˆ° $(s_{i,t},a_{i,t},r_{i,t},\text{done}_{i,t})$
        
    2. ç”¨å½“å‰çš„ VÏ• è®¡ç®— $\delta_{i,t}$,å†**å‘åé€’æ¨**å¾— $\hat A_{i,t}$ï¼Œå¹¶ä»¤ $\hat R_{i,t}=\hat A_{i,t}+V_\phi(s_{i,t})$
        
    3. åˆå§‹åŒ–æ–°å‚æ•°ï¼šÎ¸â€²â†Î¸ï¼ˆæ—§ç­–ç•¥å‚æ•°çš„æ‹·è´ï¼‰ã€‚
        
    4. åœ¨è¿™åŒä¸€æ‰¹æ•°æ®ä¸Šï¼Œåš **K ä¸ª epoch**ã€è‹¥å¹² mini-batchï¼š
        
        1. è®¡ç®— $r_{i,t}(\theta)$ã€clip åçš„ç­–ç•¥æœ€å¤§Advantageï¼›
            
            - **æ—§ç­–ç•¥åˆ†æ¯** $\pi_\theta(a_t|s_t)$æ˜¯å›ºå®šçš„ï¼ˆæ—§ç­–ç•¥ï¼Œæ¥è‡ªé‡‡æ ·ï¼‰ã€‚
                
            - **æ–°ç­–ç•¥åˆ†å­** $\pi_{\theta'}(a_t|s_t)$æ¯æ¬¡éƒ½ä¼šéšç€ Î¸â€² æ›´æ–°è€Œæ”¹å˜ã€‚
                
        2. è®¡ç®—ä»·å€¼ MSE é¡¹ $(V_\phi-\hat R)^2$
            
        3. è®¡ç®—ç†µé¡¹ï¼›
            
        4. æŒ‰ä¸Šé¢çš„ **ç»éªŒæŸå¤±** $L(\theta,\phi)$ åä¼ æ›´æ–°ã€‚
            
    5. ç»“æŸåæŠŠ $\pi_{\text{old}}\leftarrow \pi_{\theta}$ï¼Œè¿›å…¥ä¸‹ä¸€æ‰¹ã€‚
        

## 3.4 PPO LLM

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ 1. Prompt æ•°æ®ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰ â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚

â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ 2. Policy æ¨¡å‹ (LLM, Ï€Î¸) â”‚

â”‚ ç”Ÿæˆå¤šä¸ª candidate å›ç­” y â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚

â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ 3. å¥–åŠ±æ¨¡å‹ RM(x,y) â”‚

â”‚ æ ¹æ®äººç±»åå¥½è®­ç»ƒå¾—åˆ° â”‚

â”‚ ç»™æ¯ä¸ªå›ç­”æ‰“åˆ† reward â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚

â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ 4. åŠ  KL penalty â”‚

â”‚ R(x,y) = RM(x,y) - Î»Â·KL(...)â”‚

â”‚ çº¦æŸæ–°ç­–ç•¥åˆ«åç¦»å‚è€ƒæ¨¡å‹ â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚

â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ 5. PPO æ›´æ–° â”‚

â”‚ - è®¡ç®—æ¦‚ç‡æ¯” r_t â”‚

â”‚ - ç”¨ clip é™åˆ¶æ›´æ–°å¹…åº¦ â”‚

â”‚ - è®©å¥½å›ç­”æ¦‚ç‡â†‘ï¼Œåå›ç­”â†“ â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚

â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ 6. æ›´æ–°åçš„ Policy æ¨¡å‹ â”‚

â”‚ Ï€Î¸' ç”Ÿæˆæ›´ç¬¦åˆäººç±»åå¥½çš„è¾“å‡º â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 3.4.1 PPO
#### 3.4.1.1 å›¾è§£

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=MmUyZDE5MWE3ZTNmOGFkY2M2OGRiYTkyMjBhZDY4ZDVfS3dBYlZ5bEltZE84cW0wb2ljQlYyTFpjbEtzY3hvNE9fVG9rZW46STFWdGJ5ZXZlb1kyb0l4Z2lBYmw1VzkxZzZiXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=YzI5MTNmOGNlMTg3OGYxZWZjMGRmZWY5Zjc1YWY4ZDhfTHRGZkg2T2FHSmV2cVZpNjh0SzBCVnA5QU5JZVZoRDdfVG9rZW46WXN0emJsZlFob09PTEd4MXhjeGxBWmdtZ1JmXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)

![](https://susfq45zc9c0.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=OWI2NzAzNWFmOWJhNjExZWEzNTEwYWY3YTExYjYyOGFfMlhwTjVldGRiUWtMd09DSmFrMDFZMUQyd2dXVFVsU2tfVG9rZW46RXNhQ2JCMm9ab2VJQVd4OFV0OWwzbkRVZ2NnXzE3NTkwNTY1NDA6MTc1OTA2MDE0MF9WNA)



#### 3.4.1.2 PPO ä¸€è½®è®­ç»ƒ

ã€ä»»åŠ¡/ç¤ºä¾‹ã€‘
	Prompt $q_i=$ "Eric has a banana"ï¼›ç”¨å†»ç»“çš„ $\pi_{\mathrm{old}}$ ç”Ÿæˆå›å¤
	$o_{i,1:T_i}=$ "â No", ",", "â Yuxuan", "â steal", "â it", ",", "â so", "â Eric", "â has", "â zero", "ã€‚"
1. è®°å·
	- çŠ¶æ€ä¸åŠ¨ä½œï¼š
	  $$s_{i,t}=(q_i,\, o_{i,<t}),\quad a_{i,t}=o_{i,t}.$$
	- ç­–ç•¥ä¸ä»·å€¼ï¼šå†»ç»“è¡Œä¸ºç­–ç•¥ $\pi_{\mathrm{old}}$ï¼Œå½“å‰å¯è®­ç»ƒç­–ç•¥ $\pi_\theta$ï¼Œå‚è€ƒæ¨¡å‹ $\pi_{\mathrm{ref}}$ï¼Œä»·å€¼ç½‘ç»œ $V_\phi$ã€‚
	- ä»…å¯¹â€œç”Ÿæˆæ®µâ€è®¡ç®—æŸå¤±ï¼ˆprompt token è¢« maskï¼‰ã€‚


2. Rolloutï¼šç”¨ $\pi_{\mathrm{old}}$ é€ token ç”Ÿæˆå¹¶ç¼“å­˜å¯¹æ•°æ¦‚ç‡

	å¯¹æ¯ä¸ªæ ·æœ¬ iã€æ¯ä¸ªç”Ÿæˆæ­¥ $t=1..T_i$ï¼Œç¼“å­˜ï¼š
	$$\log \pi_{\mathrm{old}}(a_{i,t}\mid s_{i,t}),\qquad \log \pi_{\mathrm{ref}}(a_{i,t}\mid s_{i,t}).$$
	
	ç¤ºä¾‹ä¸­çš„ â€œâ zeroâ€ æ­¥ï¼š
	$$s_{i,t}=(q_i,\text{`â No`},`,`,\ldots,\text{`â has`}),\quad a_{i,t}=\text{`â zero`}.$$


3. å¥–åŠ±æ•´å½¢ï¼ˆKL in rewardï¼‰+ æœ«ç«¯å¥–åŠ±æ¨¡å‹
	
	å®šä¹‰å•æ ·æœ¬ KL è¿‘ä¼¼ï¼š
	$$\mathrm{KL}_{i,t}\ \approx\ \log \pi_{\mathrm{old}}(a_{i,t}\!\mid s_{i,t})\;-\;\log \pi_{\mathrm{ref}}(a_{i,t}\!\mid s_{i,t}).$$
	
	é€æ­¥å³æ—¶å¥–åŠ±ï¼š
	$$
	r_{i,t}=
	\begin{cases}
	-\beta\,\mathrm{KL}_{i,t}, & t<T_i,\\[4pt]
	R_\psi\!\big(q_i,\,o_{i,1:T_i}\big)\;-\;\beta\,\mathrm{KL}_{i,T_i}, & t=T_i.
	\end{cases}
	$$
	
	ï¼ˆè‹¥æ”¹ç”¨â€œKL in lossâ€ï¼Œåˆ™æ­¤å¤„ $r_{i,t}$ ä¸å« KLï¼Œæ”¹åœ¨ç¬¬ 5) æ­¥åŠ å…¥ $\beta\,\mathrm{KL}(\pi_\theta\|\pi_{\mathrm{ref}})$ã€‚ä¸¤ç§å†™æ³•æ‹©ä¸€å³å¯ã€‚ï¼‰
	
	- è‹¥ Ï€old(atâˆ£st)â€…â€Š<â€…â€ŠÏ€ref(atâˆ£st)\pi_{\text{old}}(a_t|s_t)\;<\;\pi_{\text{ref}}(a_t|s_t)Ï€oldâ€‹(atâ€‹âˆ£stâ€‹)<Ï€refâ€‹(atâ€‹âˆ£stâ€‹)ï¼Œåˆ™
    
    logâ¡Ï€oldâˆ’logâ¡Ï€ref<0Â â‡’Â rtKL>0,\log \pi_{\text{old}}-\log \pi_{\text{ref}}<0\ \Rightarrow\ r_t^{\mathrm{KL}}>0,logÏ€oldâ€‹âˆ’logÏ€refâ€‹<0Â â‡’Â rtKLâ€‹>0,
    
    è¿™ä¼šæŠŠè¿™æ¡æ ·æœ¬çš„ **ä¼˜åŠ¿ A^t\hat A_tA^tâ€‹** å¾€æ­£æ–¹å‘æ¨ã€‚
	    
- PPO çš„ actor æ›´æ–°ï¼ˆæœªè§¦å‘ clip æ—¶ï¼‰å¯¹è¿™ä¸€æ¡æ ·æœ¬çš„æ–¹å‘æ˜¯
    
    âˆ‡Î¸(ÏtA^t)Â âˆÂ A^tÂ âˆ‡Î¸logâ¡Ï€Î¸(atâˆ£st),\nabla_\theta\big(\rho_t\hat A_t\big)\ \propto\ \hat A_t\ \nabla_\theta \log\pi_\theta(a_t|s_t),âˆ‡Î¸â€‹(Ïtâ€‹A^tâ€‹)Â âˆÂ A^tâ€‹Â âˆ‡Î¸â€‹logÏ€Î¸â€‹(atâ€‹âˆ£stâ€‹),
    
    **A^t>0\hat A_t>0A^tâ€‹>0** å°±æŠŠ **Ï€Î¸(atâˆ£st)\pi_\theta(a_t|s_t)Ï€Î¸â€‹(atâ€‹âˆ£stâ€‹)** **è°ƒå¤§**ï¼ˆæ›´æ„¿æ„åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡é‡Œè¯´å‡º `zero`ï¼‰ã€‚

4. Critic ç›®æ ‡ï¼šTDã€GAE ä¸å›æŠ¥ï¼ˆå¸¸å– $\gamma=1$ï¼‰

	è®¾ $V_\phi(s_{i,T_i+1})=0$ã€‚
	
	TD æ®‹å·®ï¼š
	$$\delta_{i,t}=r_{i,t}+\gamma\,V_\phi(s_{i,t+1})-V_\phi(s_{i,t}).$$
	
	GAE é€’æ¨ï¼ˆä»åå¾€å‰ï¼‰ï¼š
	$$
	\hat A_{i,T_i}=\delta_{i,T_i},\qquad
	\hat A_{i,t}=\delta_{i,t}+\gamma\lambda\,\hat A_{i,t+1}\quad (t=T_i-1,\ldots,1).
	$$
	
	Value çš„ç›‘ç£ç›®æ ‡ï¼ˆå›æŠ¥ï¼‰ï¼š
	$$\hat G_{i,t}=\hat A_{i,t}+V_\phi(s_{i,t}).$$
	
	å¯¹æœ¬æ‰¹æ‰€æœ‰â€œç”Ÿæˆ tokenâ€çš„ä¼˜åŠ¿åšæ ‡å‡†åŒ–ï¼ˆå±•å¹³æ€»æ•°ä¸º $M=\sum_i T_i$ï¼‰ï¼š
	$$\hat A \leftarrow \frac{\hat A-\mathrm{mean}(\hat A)}{\mathrm{std}(\hat A)+\varepsilon}.$$


5. Actorï¼ˆPPO-clipï¼‰
	
	ç­–ç•¥æ¦‚ç‡æ¯”ï¼š
	$$
	\rho_{i,t}
	=\frac{\pi_\theta(a_{i,t}\!\mid s_{i,t})}{\pi_{\mathrm{old}}(a_{i,t}\!\mid s_{i,t})}
	=\exp\!\Big(\log\pi_\theta(a_{i,t}\!\mid s_{i,t})-\log\pi_{\mathrm{old}}(a_{i,t}\!\mid s_{i,t})\Big).
	$$
	
	ç­–ç•¥ç›®æ ‡ï¼ˆåœ¨æ‰€æœ‰ç”Ÿæˆ token ä¸Šå–å¹³å‡ï¼‰ï¼š
	$$
	L_{\mathrm{policy}}(\theta)=
	\frac{1}{M}\sum_{i,t}\min\!\Big(\rho_{i,t}\,\hat A_{i,t},\ \mathrm{clip}(\rho_{i,t},1-\epsilon,1+\epsilon)\,\hat A_{i,t}\Big).
	$$


6. å…¶ä»–é¡¹ï¼šValue / Entropy /ï¼ˆå¯é€‰ï¼‰KL-in-loss
	
	Value æŸå¤±ï¼š
	$$
	L_{\mathrm{value}}(\phi)=\frac{1}{M}\sum_{i,t}\frac{1}{2}\Big(V_\phi(s_{i,t})-\hat G_{i,t}\Big)^2.
	$$
	
	ç†µæ­£åˆ™ï¼ˆä½ çš„æ­£ç¡®æ ¼å¼ï¼‰ï¼š
	$$
	H\!\big(\pi_\theta(\cdot\mid s_{i,t})\big) \;=\; -\sum_a \pi_\theta(a\mid s_{i,t}) \,\log \pi_\theta(a\mid s_{i,t}).
	$$
	åŠ å…¥æ€»æŸå¤±çš„ç†µé¡¹ï¼š
	$$
	L_{\mathrm{ent}}(\theta) \;=\; -\,\frac{1}{M}\sum_{i,t} H\!\big(\pi_\theta(\cdot\mid s_{i,t})\big).
	$$
	
	ï¼ˆå¯é€‰ï¼‰è‹¥ä¸ç”¨â€œKL in rewardâ€ï¼Œé‡‡ç”¨â€œKL in lossâ€ï¼š
	$$
	L_{\mathrm{KL}}(\theta)=\frac{1}{M}\sum_{i,t}\mathrm{KL}\!\big(\pi_\theta(\cdot\mid s_{i,t})\ \|\ \pi_{\mathrm{ref}}(\cdot\mid s_{i,t})\big).
	$$
	
	æ€»æŸå¤±ï¼ˆæœ€å°åŒ–ï¼›è‹¥ KL å·²è¿›å¥–åŠ±ï¼Œåˆ™çœç•¥æœ€åä¸€é¡¹ï¼‰ï¼š
$$
\min_{\theta,\phi}\quad
-\;L_{\mathrm{policy}}(\theta)\;+\;c_v\,L_{\mathrm{value}}(\phi)\;-\;c_H\,L_{\mathrm{ent}}(\theta)\;+\;\beta\,L_{\mathrm{KL}}(\theta).
$$

7. è®­ç»ƒç»†èŠ‚ï¼ˆä¸å›¾ä¸€è‡´ï¼‰
	
	- å°†æœ¬æ‰¹ç”Ÿæˆ token å±•å¹³ã€æ‰“ä¹±ï¼Œåš $K$ ä¸ª epoch çš„å°æ‰¹ SGDï¼ˆAdamWï¼›æ¢¯åº¦è£å‰ªï¼‰ã€‚
	- åªåœ¨ç”Ÿæˆæ®µä¸Šè®¡ç®—æŸå¤±ï¼ˆprompt token maskï¼‰ã€‚
	- å¯è‡ªé€‚åº”è°ƒ $\beta$ ä»¥æ§åˆ¶å‚è€ƒ KL ç›®æ ‡åŒºé—´ã€‚

8. è½®æœ«
	
	- ä¸¢å¼ƒæœ¬æ‰¹æ•°æ®ï¼›
	- åˆ·æ–°è¡Œä¸ºç­–ç•¥ï¼š$\pi_{\mathrm{old}}\leftarrow \pi_\theta$ï¼›
	- è¿›å…¥ä¸‹ä¸€è½®ï¼šç”¨æ–°çš„ $\pi_{\mathrm{old}}$ é‡æ–° rolloutã€‚

ã€è¡¥å……ã€‘è‹¥è¦åœ¨æ–‡æœ¬ä¸­ç©¿æ’ç¤ºä¾‹ tokenï¼ˆå¦‚ `â zero`ï¼‰çš„å•æ­¥å±•å¼€ï¼Œç›´æ¥æŠŠ $a_{i,t}$ ç½®ä¸ºè¯¥ tokenï¼Œå¹¶åœ¨ä¸Šå¼é€æ­¥ä»£å…¥å³å¯ã€‚
